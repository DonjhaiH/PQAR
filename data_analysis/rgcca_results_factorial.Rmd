---
title: "factorial_rgcca_svm_results"
output: html_document
date: "2024-07-16"
---

# import data and create preliminary data frames
```{r}

#import data
#pet data
pet_ad <- read.table("/Users/donjhaiholland/PQAR_Project/PETdata_AD_centered.txt", header=FALSE)
pet_cn <- read.table("/Users/donjhaiholland/PQAR_Project/PETdata_CN_centered.txt", header=FALSE)
#snp data
snp_ad <- read.table("/Users/donjhaiholland/PQAR_Project/SNPdata_AD_centered.txt", header=FALSE)
snp_cn <- read.table("/Users/donjhaiholland/PQAR_Project/SNPdata_CN_centered.txt", header=FALSE)
#t1 data
t1_ad <- read.table("/Users/donjhaiholland/PQAR_Project/T1data_AD_centered.txt", header=FALSE)
t1_cn <- read.table("/Users/donjhaiholland/PQAR_Project/T1data_CN_centered.txt", header=FALSE)

cn_variables <- read.csv("/Users/donjhaiholland/PQAR_Project/variable_name_cn.csv", header=T)
ad_variables <- read.csv("/Users/donjhaiholland/PQAR_Project/variable_name_ad.csv", header=T)

library(dplyr)
id <- read.table("/Users/donjhaiholland/PQAR_Project/ImgGWAS_subjects.txt", header=T)
demographics <- read.csv("/Users/donjhaiholland/PQAR_Project/ADNIMERGE.csv", header=T)

# sample id/demographics 

#select id and status column in id table
id_clean <- id %>%
  select(
    status,
    ID = alternative_id_1)

#filter baseline cases and select needed demographics
demographics_clean <- demographics %>%
  filter(VISCODE == "bl") %>%
  select(
    ID = PTID,
    age = AGE,
    gender = PTGENDER,
    code = VISCODE,
    race = PTRACCAT,
    ethnicity = PTETHCAT)

# merge tables together
dem_id  <-  merge(id_clean, demographics_clean, by = "ID" , sort=F)
dim(dem_id)

# check table for sample size match
#dem_id %>%
  #group_by(status) %>%
  #count(status)

# separate each group into its on df
cn_dem <- dem_id %>% 
  filter(status == "CN")
dim(cn_dem)

ad_dem <- dem_id %>% 
  filter(status == "AD")
dim(ad_dem)


# adding Variable names to columns

add_var_names <- function(matrix, df) {
  
  # transpose matrix
  matrix_t <- t(matrix)
  
  # transpose df, convert to vector, add column names to matrix
  colnames(matrix_t) <-  as.vector(unlist(c(t(df))))
  
  # convert to dataframe
  df_new = as.data.frame(matrix_t)
  
  return (df_new)
}

pet_var1 <- add_var_names(pet_cn, roi_names)
t1_var1 <- add_var_names(t1_cn, roi_names)
snp_var1 <- add_var_names(snp_cn, snp_names)

colnames(pet_var1) <- paste0("pet_cn_", colnames(pet_var1))
colnames(snp_var1) <- paste0("snp_cn_", colnames(snp_var1))
colnames(t1_var1) <- paste0("t1_cn_", colnames(t1_var1))


pet_var <- add_var_names(pet_ad, roi_names)
t1_var <- add_var_names(t1_ad, roi_names)
snp_var <- add_var_names(snp_ad, snp_names)

colnames(pet_var) <- paste0("pet_ad_", colnames(pet_var))
colnames(snp_var) <- paste0("snp_ad_", colnames(snp_var))
colnames(t1_var) <- paste0("t1_ad_", colnames(t1_var))

```

# Create data frames for sparse model
```{r setup, include=FALSE}


## create data frames for sparse model

ad <- as.data.frame(t(rbind(pet_ad, snp_ad, t1_ad)))
cn <- as.data.frame(t(rbind(pet_cn, snp_cn, t1_cn)))

cn2 <- cbind(cn, cn_dem$ID)
colnames(cn2)[638] = "ID"

row.names(cn2) <- cn2$ID

cn2 <- cn2[, -638]

ad2<- cbind(ad, ad_dem$ID)
colnames(ad2)[638] = "ID"

row.names(ad2) <- ad2$ID

ad2 <- ad2[, -638]


ad_group = list((pet_var1),(snp_var1),(t1_var1))
cn_group = list((pet_var),(snp_var),(t1_var))

```


# rgcca optimal tau (rgcca_permutation)
```{r}
set.seed(33)

tau_values= seq(0.01, 1, length.out = 30)
tau_matrix <- matrix(tau_values, ncol = 3, nrow = 30)
#print(tau_matrix)

cn_perm2 <- rgcca_permutation(
  blocks=cn_group,
  connection = NULL,
  scale = FALSE,
  par_type = "tau",
  par_value = tau_matrix,
  n_perms = 20,
  scheme = "factorial",
  verbose = TRUE)

cn_optimal_tau <- cn_perm$best_params
print(cn_optimal_tau)

plot(cn_perm2)


#AD Optimal Tau


ad_perm <- rgcca_permutation(
  blocks=ad_group,
  connection = NULL,
  scale = FALSE,
  par_type = "tau",
  par_length = 50,
  n_perms = 50,
  scheme = "factorial",
  verbose = TRUE)

ad_optimal_tau <- ad_perm$best_params
print(ad_optimal_tau)
```

# rgcca implemntation
```{r}
# Set the scheme for covariance maximization
scheme <- "factorial"
#cn_ncomp <- c(1,1,1)
#cn_sparsity <- c(0.2,0.2,0.2)

# Fit the RGCCA model
cn_rgcca <- rgcca(
  blocks = cn_group,
  connection = NULL,
  tau = cn_optimal_tau,
  ncomp = 1,
  scheme = scheme,
  scale = FALSE,
  init= "svd",
  verbose= TRUE,
  sparsity = 1
)

plot(cn_rgcca)



# Set the scheme for covariance maximization


# Fit the RGCCA model
ad_rgcca <- rgcca(
  blocks = ad_group,
  connection = NULL,
  tau = ad_optimal_tau,
  ncomp = 1,
  scheme = scheme,
  scale = FALSE,
  init= "svd",
  verbose= TRUE,
  sparsity = 1
)

plot(ad_rgcca)
```

# top 10 varibles by name
```{r}

variable_weights_CN <- cn_rgcca$a
ncomp_values <- c(1, 1, 1)

# Function to extract top ten variables by weight magnitude
top_ten_CN <- function(weights, n_top = 10) {
  abs_weights <- abs(weights)
  top_indices <- order(abs_weights, decreasing = TRUE)[1:n_top]
  return(data.frame(Variable = names(weights)[top_indices], Weight = weights[top_indices]))
}

# Initialize a list to store the results for each block and component
top_weights_list <- list()

# Loop through each block and each component to print the top ten variables
for (i in seq_along(variable_weights_CN)) {
  cat(sprintf("Top 10 variable weights for block %d:\n", i))
  
  for (j in 1:ncomp_values[i]) {
    cat(sprintf("Component %d:\n", j))
    
    # Ensure the weights have names (variable names)
    if (is.null(names(variable_weights_CN[[i]][, j]))) {
      names(variable_weights_CN[[i]][, j]) <- paste0("V", 1:nrow(variable_weights_CN[[i]]))
    }
    
    # Extract the top weights
    top_weights_CN <- top_ten_CN(variable_weights_CN[[i]][, j])
    
    # Print the top weights
    print(top_weights_CN)
    cat("\n")
    
    # Store the top weights in the list with a unique name
    top_weights_list[[paste0("block", i, "_component", j)]] <- top_weights_CN
  }
}



variable_weights_AD <- ad_rgcca$a
ncomp_values <- c(1, 1, 1)

# Function to extract top ten variables by weight magnitude
top_ten_AD <- function(weights, n_top = 10) {
  abs_weights <- abs(weights)
  top_indices <- order(abs_weights, decreasing = TRUE)[1:n_top]
  return(data.frame(Variable = names(weights)[top_indices], Weight = weights[top_indices]))
}

# Initialize a list to store the results for each block and component
top_weights_list_ad <- list()

# Loop through each block and each component to print the top ten variables
for (i in seq_along(variable_weights_AD)) {
  cat(sprintf("Top 10 variable weights for block %d:\n", i))
  
  for (j in 1:ncomp_values[i]) {
    cat(sprintf("Component %d:\n", j))
    
    # Ensure the weights have names (variable names)
    if (is.null(names(variable_weights_AD[[i]][, j]))) {
      names(variable_weights_AD[[i]][, j]) <- paste0("V", 1:nrow(variable_weights_AD[[i]]))
    }
    
    # Extract the top weights
    top_weights_AD <- top_ten_AD(variable_weights_AD[[i]][, j])
    
    # Print the top weights
    print(top_weights_AD)
    cat("\n")
    
    # Store the top weights in the list with a unique name
    top_weights_list_ad[[paste0("block", i, "_component", j)]] <- top_weights_AD
  }
}
```

# Get top 10 for model (w/o variable names)
```{r}

# Function to extract the top 10 absolute weight vectors
get_top_10 <- function(matrix) {
  # Convert matrix to a vector with absolute values
  abs_values <- abs(matrix)
  
  # Get the indices of the top 10 values
  top_10 <- order(abs_values, decreasing = TRUE)[1:10]
  
  return(top_10)
}

cn_pet_w <- get_top_10(cn_rgcca$a$block1)
cn_snp_w <- get_top_10(cn_rgcca$a$block2)
cn_t1_w <-  get_top_10(cn_rgcca$a$block3)

ad_pet_w <- get_top_10(ad_rgcca$a$block1)
ad_snp_w <-  get_top_10(ad_rgcca$a$block2)
ad_t1_w <-  get_top_10(ad_rgcca$a$block3)

# cn_dem_var[1:nrow(cn), c(1:7, cn_snp_w)]
# cn_dem_var[1:nrow(cn), c(1:7, cn_snp_w, cn_pet_w, cn_t1_w)] --> use this for cn, then do the same for ad
top_10_cn_pet <- cn2[,c(638:640, cn_pet_w)]
top_10_cn_snp <- cn2[,c(638:640,cn_snp_w)]
top_10_cn_t1 <- cn2[ , c(638:640,cn_t1_w)]

top_10_ad_pet <- ad2[,c(638:640,ad_pet_w )]
top_10_ad_snp <- ad2[,c(638:640,ad_snp_w)]
top_10_ad_t1 <- ad2[,c(638:640,ad_t1_w)]

#top_10_cn_pet
#top_10_cn_snp
#top_10_cn_t1 

top_cn <- cbind(top_10_cn_pet, top_10_cn_snp, top_10_cn_t1)
#top_cn_df <- cbind(top_cn, cn_dem_var$age, cn_dem_var$gender, cn_dem_var$race)



#top_10_ad_snp
#top_10_ad_pet
#top_10_ad_t1 

top_ad <- cbind(top_10_ad_pet, top_10_ad_snp, top_10_ad_t1)

```

# SparseSVM
```{r}

top_cn$response <- 0
top_ad$response <- 1

# Ensuring the column names are the same
colnames(top_ad) <- colnames(top_cn)

# Make column names unique
top_cn <- make_unique_colnames(top_cn)
top_ad <- make_unique_colnames(top_ad)

# Combining the dataframes using rbind
combined_df1 <- rbind(top_cn, top_ad)

# Display the combined data frame
#head(combined_df1)


# Shuffle the rows
shuffled_df <- combined_df1 %>% sample_n(nrow(.))

# Display the shuffled dataframe
print(shuffled_df)

#combined_df$response
response <- combined_df1$response

# Set seed for reproducibility
set.seed(333)

# Split the data into training and testing sets
split <- initial_split(combined_df1, strata = response, prop = 7/10)
train <- training(split)
test <- testing(split)

# Create the predictor matrix (excluding the response column)
x_train <- model.matrix(response ~ ., train)[,-1]
y_train <- train$response

dim(x_train) 

x_test <- model.matrix(response ~ ., test)[,-1]
y_test <- test$response

set.seed(333)

cv_sparse_svm <- cv.sparseSVM(x_train, y_train, nfolds = 5, alpha = 1, 
                              lambda = 10^seq(-6, 1, length = 100))

# Get the best lambda value
best_lambda2 <- cv_sparse_svm$lambda.min

# Predict on the test set
predicted_classes2 <- predict(cv_sparse_svm, X = x_test, lambda = best_lambda2, type = "class")


# Create a confusion matrix
#confusion_matrix_sparse_svm <- confusionMatrix(as.factor(predicted_classes2), as.factor(y_test))
#print(confusion_matrix_sparse_svm)

# Convert predicted_classes2 and y_test to factors with labels "CN" and "AD"
predicted_classes2 <- factor(predicted_classes2, levels = c(0, 1), labels = c("CN", "AD"))
y_test <- factor(y_test, levels = c(0, 1), labels = c("CN", "AD"))

# Create the confusion matrix
confusion_matrix_sparse_svm <- confusionMatrix(predicted_classes2, y_test)
print(confusion_matrix_sparse_svm)


```


```{r}
# Load necessary libraries
library(tidymodels)
library(sparseSVM)
library(caret)
library(dplyr)

# Ensure combined3 is a data frame
combined3 <- as.data.frame(combined3)

# Make column names unique
colnames(combined3) <- make.unique(colnames(combined3))

# Ensure response column is properly set
combined3$response <- c(rep(0, 332), rep(1, 217))

# Initialize variables to store the results
specificity_list <- numeric(100)
sensitivity_list <- numeric(100)
accuracy_list <- numeric(100)
mcc_list <- numeric(100)
non_zero_coefficients_list <- vector("list", 100)

for (i in 1:100) {
  set.seed(333 + i)  # Change seed for each iteration

  # Shuffle the rows
  shuffled_df <- combined3 %>% sample_n(nrow(.))

  # Split the data into training and testing sets with stratification
  split <- initial_split(shuffled_df, strata = response, prop = 7/10)
  train <- training(split)
  test <- testing(split)

  # Ensure complete cases
  train <- train[complete.cases(train), ]
  test <- test[complete.cases(test), ]

  # Convert categorical variables to numeric
  train$Gender <- as.numeric(factor(train$Gender, levels = c("Male", "Female")))
  train$Race <- as.numeric(factor(train$Race, levels = c("White", "Black", "Asian", "Am Indian/Alaskan", "More than one")))

  test$Gender <- as.numeric(factor(test$Gender, levels = c("Male", "Female")))
  test$Race <- as.numeric(factor(test$Race, levels = c("White", "Black", "Asian", "Am Indian/Alaskan", "More than one")))

  # Create the predictor matrix (excluding the response column)
  x_train <- as.matrix(train %>% select(-response))
  y_train <- train$response

  x_test <- as.matrix(test %>% select(-response))
  y_test <- test$response

  # Fit the sparse SVM model with cross-validation
  cv_sparse_svm <- cv.sparseSVM(x_train, y_train, nfolds = 5, alpha = 1, lambda = 10^seq(-6, 1, length = 100))

  # Get the best lambda value
  best_lambda2 <- cv_sparse_svm$lambda.min

  # Predict on the test set
  predicted_classes2 <- predict(cv_sparse_svm, X = x_test, lambda = best_lambda2, type = "class")

  # Convert predicted_classes2 and y_test to factors with labels "CN" and "AD"
  predicted_classes2 <- factor(predicted_classes2, levels = c(0, 1), labels = c("CN", "AD"))
  y_test <- factor(y_test, levels = c(0, 1), labels = c("CN", "AD"))

  # Create the confusion matrix
  confusion_matrix_sparse_svm <- confusionMatrix(predicted_classes2, y_test, positive = "AD")
  
  specificity_list[i] <- confusion_matrix_sparse_svm$byClass["Specificity"]
  sensitivity_list[i] <- confusion_matrix_sparse_svm$byClass["Sensitivity"]
  accuracy_list[i] <- confusion_matrix_sparse_svm$overall["Accuracy"]
  
  # Calculate MCC using the true and predicted classes directly
  MCC <- mccr::mccr(as.numeric(as.character(y_test)), as.numeric(as.character(predicted_classes2)))
  mcc_list[i] <- MCC
  
  # Extract non-zero coefficients
  coefficients <- coef(cv_sparse_svm, s = best_lambda2)
  non_zero_indices <- which(coefficients != 0)
  non_zero_coefficients_list[[i]] <- colnames(x_train)[non_zero_indices]
}

# Calculate averages
avg_specificity <- mean(specificity_list, na.rm = TRUE)
avg_sensitivity <- mean(sensitivity_list, na.rm = TRUE)
avg_accuracy <- mean(accuracy_list, na.rm = TRUE)
avg_mcc <- mean(mcc_list, na.rm = TRUE)

cat("Average Specificity:", avg_specificity, "\n")
cat("Average Sensitivity:", avg_sensitivity, "\n")
cat("Average Accuracy:", avg_accuracy, "\n")
cat("Average MCC:", avg_mcc, "\n")

# Print the non-zero coefficients for each iteration




```



```{r}
# Load necessary libraries
library(tidymodels)
library(sparseSVM)
library(caret)
library(dplyr)
library(mccr)  # Load the mccr package

# Function to extract the top 10 absolute weight vectors
get_top_10 <- function(matrix) {
  # Convert matrix to a vector with absolute values
  abs_values <- abs(matrix)
  
  # Get the indices of the top 10 values
  top_10 <- order(abs_values, decreasing = TRUE)[1:10]
  
  return(top_10)
}

#cn_dem_var[order(abs(cn_rgcca$a$block2), decreasing = T)[1:10], ]
#cn_dem_var[379,]
#cn[379,]

#ad[order(abs(ad_rgcca$a$block2), decreasing = T)[1:10], ]


cn_pet_w <- get_top_10(cn_rgcca$a$block1)
cn_snp_w <- get_top_10(cn_rgcca$a$block2)
cn_t1_w <-  get_top_10(cn_rgcca$a$block3)

ad_pet_w <- get_top_10(ad_rgcca$a$block1)
ad_snp_w <-  get_top_10(ad_rgcca$a$block2)
ad_t1_w <-  get_top_10(ad_rgcca$a$block3)

# cn_dem_var[1:nrow(cn), c(1:7, cn_snp_w)]
# cn_dem_var[1:nrow(cn), c(1:7, cn_snp_w, cn_pet_w, cn_t1_w)] --> use this for cn, then do the same for ad
top_10_cn_pet <- combined_dems[,c(1:3, cn_pet_w)]
top_10_cn_snp <- combined_dems[,cn_snp_w]
top_10_cn_t1 <- combined_dems[ , cn_t1_w]



top_10_ad_pet <-combined_dems[,ad_pet_w]
top_10_ad_snp <- combined_dems[,ad_snp_w]
top_10_ad_t1 <-combined_dems[,ad_t1_w]

#top_10_cn_pet
#top_10_cn_snp
#top_10_cn_t1 

#top_cn <- merge(top_10_cn_pet, top_10_cn_snp, by = "ID" , sort=F)
top_cn <- cbind(top_10_cn_pet, top_10_cn_snp, top_10_cn_t1)
#top_cn_df <- cbind(top_cn, cn_dem_var$age, cn_dem_var$gender, cn_dem_var$race)

dim(top_cn)
#top_10_ad_snp
#top_10_ad_pet
#top_10_ad_t1 

top_ad <- cbind(top_10_ad_pet, top_10_ad_snp, top_10_ad_t1)


combined3 <- cbind(top_cn, top_ad)

# Ensure combined3 is a data frame
combined3 <- as.data.frame(combined3)

# Identify and drop duplicate columns
duplicated_columns <- duplicated(t(combined3))
combined3 <- combined3[, !duplicated_columns]

# Ensure response column is properly set
combined3$response <- c(rep(0, 332), rep(1, 217))

# Initialize variables to store the results
specificity_list <- numeric(100)
sensitivity_list <- numeric(100)
accuracy_list <- numeric(100)
mcc_list <- numeric(100)
non_zero_coefficients_list <- vector("list", 100)

for (i in 1:100) {
  set.seed(333 + i)  # Change seed for each iteration

  # Shuffle the rows
  shuffled_df <- combined3 %>% sample_n(nrow(.))

  # Split the data into training and testing sets with stratification
  split <- initial_split(shuffled_df, strata = response, prop = 7/10)
  train <- training(split)
  test <- testing(split)

  # Ensure complete cases
  train <- train[complete.cases(train), ]
  test <- test[complete.cases(test), ]

  # Convert categorical variables to numeric
  train$Gender <- as.numeric(factor(train$Gender, levels = c("Male", "Female")))
  train$Race <- as.numeric(factor(train$Race, levels = c("White", "Black", "Asian", "Am Indian/Alaskan", "More than one")))

  test$Gender <- as.numeric(factor(test$Gender, levels = c("Male", "Female")))
  test$Race <- as.numeric(factor(test$Race, levels = c("White", "Black", "Asian", "Am Indian/Alaskan", "More than one")))

  # Create the predictor matrix (excluding the response column)
  x_train <- as.matrix(train %>% select(-response))
  y_train <- train$response

  x_test <- as.matrix(test %>% select(-response))
  y_test <- test$response

  # Fit the sparse SVM model with cross-validation
  cv_sparse_svm <- cv.sparseSVM(x_train, y_train, nfolds = 5, alpha = 1, lambda = 10^seq(-6, 1, length = 100))

  # Get the best lambda value
  best_lambda2 <- cv_sparse_svm$lambda.min

  # Predict on the test set
  predicted_classes2 <- predict(cv_sparse_svm, X = x_test, lambda = best_lambda2, type = "class")

  # Convert predicted_classes2 and y_test to numeric
  predicted_classes2 <- as.numeric(as.character(predicted_classes2))
  y_test <- as.numeric(as.character(y_test))

  # Check for NA values
  if (any(is.na(predicted_classes2)) || any(is.na(y_test))) {
    next  # Skip this iteration if there are NAs
  }

  # Create the confusion matrix
  confusion_matrix_sparse_svm <- confusionMatrix(factor(predicted_classes2, levels = c(0, 1), labels = c("CN", "AD")),
                                                 factor(y_test, levels = c(0, 1), labels = c("CN", "AD")),
                                                 positive = "AD")

  specificity_list[i] <- confusion_matrix_sparse_svm$byClass["Specificity"]
  sensitivity_list[i] <- confusion_matrix_sparse_svm$byClass["Sensitivity"]
  accuracy_list[i] <- confusion_matrix_sparse_svm$overall["Accuracy"]
  
  # Calculate MCC using the true and predicted classes directly
  MCC <- mccr::mccr(y_test, predicted_classes2)
  mcc_list[i] <- MCC
  
  # Extract non-zero coefficients
  coefficients <- coef(cv_sparse_svm, s = best_lambda2)
  non_zero_indices <- which(coefficients != 0)
  non_zero_coefficients_list[[i]] <- colnames(x_train)[non_zero_indices]
}

# Calculate averages
avg_specificity <- mean(specificity_list, na.rm = TRUE)
avg_sensitivity <- mean(sensitivity_list, na.rm = TRUE)
avg_accuracy <- mean(accuracy_list, na.rm = TRUE)
avg_mcc <- mean(mcc_list, na.rm = TRUE)

cat("Average Specificity:", avg_specificity, "\n")
cat("Average Sensitivity:", avg_sensitivity, "\n")
cat("Average Accuracy:", avg_accuracy, "\n")
cat("Average MCC:", avg_mcc, "\n")
#print(non_zero_coefficients_list)


```







```{r}

# Load necessary libraries
library(dplyr)
library(rsample)
library(sparseSVM)
library(caret)
library(mccr)

# Initialize variables to store the results
specificity_list <- numeric(100)
sensitivity_list <- numeric(100)
accuracy_list <- numeric(100)
mcc_list <- numeric(100)
non_zero_coefficients_list <- list()

for (i in 1:100) {
  # Add a response column
  top_cn$response <- 0
  top_ad$response <- 1

  # Ensure the column names are the same
  colnames(top_cn) <- colnames(top_ad)

  # Make column names unique
  top_cn <- make_unique_colnames(top_cn)
  top_ad <- make_unique_colnames(top_ad)

  # Combine the datasets
  combined_df <- rbind(top_ad, top_cn)

  set.seed(333 + i)  # Change seed for each iteration
  shuffled_df <- combined_df %>% sample_n(nrow(.))

  # Split the data into training and testing sets with stratification
  response <- shuffled_df$response
  split <- initial_split(shuffled_df, strata = response, prop = 7/10)
  train <- training(split)
  test <- testing(split)

  # Ensure complete cases
  train <- train[complete.cases(train), ]
  test <- test[complete.cases(test), ]

  # Convert categorical variables to numeric
  train$Gender <- as.numeric(factor(train$Gender, levels = c("Male", "Female")))
  train$Race <- as.numeric(factor(train$Race, levels = c("White", "Black", "Asian", "Am Indian/Alaskan", "More than one")))

  test$Gender <- as.numeric(factor(test$Gender, levels = c("Male", "Female")))
  test$Race <- as.numeric(factor(test$Race, levels = c("White", "Black", "Asian", "Am Indian/Alaskan", "More than one")))

  # Create the predictor matrix (excluding the response column)
  x_train <- as.matrix(train %>% select(-response))
  y_train <- train$response

  x_test <- as.matrix(test %>% select(-response))
  y_test <- test$response

  # Fit the sparse SVM model with cross-validation
  cv_sparse_svm <- cv.sparseSVM(x_train, y_train, nfolds = 5, alpha = 1, lambda = 10^seq(-6, 1, length = 100))

  # Get the best lambda value
  best_lambda2 <- cv_sparse_svm$lambda.min

  # Predict on the test set
  predicted_classes2 <- predict(cv_sparse_svm, X = x_test, lambda = best_lambda2, type = "class")

  # Convert predicted_classes2 and y_test to factors with labels "CN" and "AD"
  predicted_classes2 <- factor(predicted_classes2, levels = c(0, 1), labels = c("CN", "AD"))
  y_test <- factor(y_test, levels = c(0, 1), labels = c("CN", "AD"))

  # Create the confusion matrix
  confusion_matrix_sparse_svm <- confusionMatrix(predicted_classes2, y_test, positive = "AD")
  
  specificity_list[i] <- confusion_matrix_sparse_svm$byClass["Specificity"]
  sensitivity_list[i] <- confusion_matrix_sparse_svm$byClass["Sensitivity"]
  accuracy_list[i] <- confusion_matrix_sparse_svm$overall["Accuracy"]
  
  # Calculate MCC using the true and predicted classes directly
  MCC <- mccr::mccr(as.numeric(as.character(y_test)), as.numeric(as.character(predicted_classes2)))
  mcc_list[i] <- MCC
  
  # Extract non-zero coefficients
  coefficients <- coef(cv_sparse_svm, s = best_lambda2)
  non_zero_indices <- which(coefficients != 0)
  non_zero_coefficients_list[[i]] <- colnames(x_train)[non_zero_indices]
}

# Calculate averages
avg_specificity <- mean(specificity_list, na.rm = TRUE)
avg_sensitivity <- mean(sensitivity_list, na.rm = TRUE)
avg_accuracy <- mean(accuracy_list, na.rm = TRUE)
avg_mcc <- mean(mcc_list, na.rm = TRUE)

cat("Average Specificity:", avg_specificity, "\n")
cat("Average Sensitivity:", avg_sensitivity, "\n")
cat("Average Accuracy:", avg_accuracy, "\n")
cat("Average MCC:", avg_mcc, "\n")

# Print the non-zero coefficients for each iteration


```

